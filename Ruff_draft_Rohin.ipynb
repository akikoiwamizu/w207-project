{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5"
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "# This tells matplotlib not to try opening a new window for each plot.\n",
    "%matplotlib inline\n",
    "\n",
    "# General libraries.\n",
    "import re\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# SK-learn libraries for learning.\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "# SK-learn libraries for evaluation.\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import classification_report\n",
    "\n",
    "# SK-learn library for importing the newsgroup data.\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# SK-learn libraries for feature extraction from text.\n",
    "from sklearn.feature_extraction.text import *\n",
    "\n",
    "import nltk\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>12570</th>\n",
       "      <td>LONDON (Reuters) - Britain said on Monday it w...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11232</th>\n",
       "      <td>All of the real evidence of real money and re...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>807</th>\n",
       "      <td>While Donald Trump hasn t exactly made an admi...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3556</th>\n",
       "      <td>The Whiner-in-Chief humiliated himself again.T...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21550</th>\n",
       "      <td>Greg Gutfield asks the question we all would l...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15534</th>\n",
       "      <td>TOKYO (Reuters) - U.S. President Donald Trump ...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16431</th>\n",
       "      <td>LONDON (Reuters) - Failure to pass the governm...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7240</th>\n",
       "      <td>WASHINGTON (Reuters) - Republican President-el...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22620</th>\n",
       "      <td>21st Century Wire says The Silicon Valley s te...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22049</th>\n",
       "      <td>21st Century Wire says The war between the Whi...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>35918 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "12570  LONDON (Reuters) - Britain said on Monday it w...  true\n",
       "11232   All of the real evidence of real money and re...  fake\n",
       "807    While Donald Trump hasn t exactly made an admi...  fake\n",
       "3556   The Whiner-in-Chief humiliated himself again.T...  fake\n",
       "21550  Greg Gutfield asks the question we all would l...  fake\n",
       "...                                                  ...   ...\n",
       "15534  TOKYO (Reuters) - U.S. President Donald Trump ...  true\n",
       "16431  LONDON (Reuters) - Failure to pass the governm...  true\n",
       "7240   WASHINGTON (Reuters) - Republican President-el...  true\n",
       "22620  21st Century Wire says The Silicon Valley s te...  fake\n",
       "22049  21st Century Wire says The war between the Whi...  fake\n",
       "\n",
       "[35918 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>572</th>\n",
       "      <td>YANGON/NAYPYITAW (Reuters) - Members of the U....</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7053</th>\n",
       "      <td>A Texas cop is under fire after video surfaced...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13131</th>\n",
       "      <td>BRUSSELS (Reuters) - Prime Minister Theresa Ma...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14788</th>\n",
       "      <td>Low energy candidate low energy fans h/t Weas...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>852</th>\n",
       "      <td>It s only been a few days since Donald Trump a...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12009</th>\n",
       "      <td>Remember when Pelosi said it s  AFFORDABLE :</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17866</th>\n",
       "      <td>Late-night TV host Jimmy Kimmel opened his pro...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14087</th>\n",
       "      <td>BEIJING (Reuters) - Some northern Chinese citi...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19179</th>\n",
       "      <td>So much for the SCOTUS not being political Che...</td>\n",
       "      <td>fake</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10544</th>\n",
       "      <td>WASHINGTON (Reuters) - The U.S. Supreme Court ...</td>\n",
       "      <td>true</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8980 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                    text label\n",
       "572    YANGON/NAYPYITAW (Reuters) - Members of the U....  true\n",
       "7053   A Texas cop is under fire after video surfaced...  fake\n",
       "13131  BRUSSELS (Reuters) - Prime Minister Theresa Ma...  true\n",
       "14788   Low energy candidate low energy fans h/t Weas...  fake\n",
       "852    It s only been a few days since Donald Trump a...  fake\n",
       "...                                                  ...   ...\n",
       "12009      Remember when Pelosi said it s  AFFORDABLE :   fake\n",
       "17866  Late-night TV host Jimmy Kimmel opened his pro...  fake\n",
       "14087  BEIJING (Reuters) - Some northern Chinese citi...  true\n",
       "19179  So much for the SCOTUS not being political Che...  fake\n",
       "10544  WASHINGTON (Reuters) - The U.S. Supreme Court ...  true\n",
       "\n",
       "[8980 rows x 2 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fake_data=pd.read_csv('~/Desktop/w207/Final_Project/w207-project/input/fake-and-real-news-dataset/Fake.csv')\n",
    "true_data=pd.read_csv('~/Desktop/w207/Final_Project/w207-project/input/fake-and-real-news-dataset/True.csv')\n",
    "fake_data['label']='fake'\n",
    "true_data['label']='true'\n",
    "fake_corpus=fake_data[['text','label']]\n",
    "true_corpus=true_data[['text','label']]\n",
    "frames=[fake_corpus,true_corpus]\n",
    "data=pd.concat(frames)\n",
    "\n",
    "train, test = train_test_split(data, test_size=0.2)\n",
    "\n",
    "display(train)\n",
    "display(test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "frozenset({'an', 'either', 'this', 'forty', 'rather', 'most', 'themselves', 'everything', 'latter', 'interest', 'nor', 'indeed', 'co', 'almost', 'sometimes', 'have', 'twelve', 'whereafter', 'except', 'would', 'ltd', 'fifteen', 'is', 'up', 'of', 'neither', 'your', 'made', 'some', 'thin', 'call', 'though', 'elsewhere', 'himself', 'again', 'eg', 'been', 'not', 'and', 'other', 'there', 'seemed', 'hereby', 'over', 'cant', 'for', 'he', 'even', 'whereupon', 'find', 'somehow', 'any', 'serious', 'moreover', 'empty', 'him', 'we', 'why', 'ourselves', 'still', 'somewhere', 'sometime', 'one', 'where', 'five', 'ever', 'twenty', 'thereupon', 'describe', 'whenever', 'amoungst', 'yet', 'bill', 'nine', 'seems', 'from', 'whole', 'could', 'perhaps', 'first', 'eight', 'she', 'here', 'full', 'ie', 'are', 'yourselves', 'three', 'get', 'nevertheless', 'all', 'may', 'otherwise', 'thereby', 'afterwards', 'can', 'via', 'latterly', 'detail', 'once', 'those', 'much', 'thereafter', 'de', 'a', 'same', 'which', 'below', 'con', 'must', 'everyone', 'yourself', 'after', 're', 'move', 'whereby', 'out', 'nowhere', 'among', 'became', 'beyond', 'keep', 'back', 'herein', 'see', 'at', 'in', 'few', 'another', 'never', 'give', 'while', 'please', 'hers', 'also', 'formerly', 'hasnt', 'six', 'along', 'each', 'above', 'anything', 'anyhow', 'am', 'sincere', 'within', 'if', 'they', 'reuters', 'seem', 'itself', 'mostly', 'what', 'show', 'noone', 'go', 'several', 'four', 'least', 'through', 'etc', 'found', 'yours', 'throughout', 'hereupon', 'namely', 'were', 'well', 'had', 'name', 'nobody', 'front', 'hereafter', 'whence', 'that', 'couldnt', 'more', 'others', 'thence', 'during', 'often', 'but', 'none', 'whither', 'besides', 'it', 'about', 'enough', 'whom', 'further', 'hundred', 'always', 'or', 'has', 'no', 'its', 'before', 'two', 'towards', 'whose', 'due', 'i', 'only', 'therefore', 'amount', 'both', 'his', 'many', 'under', 'top', 'between', 'fifty', 'fill', 'hence', 'down', 'side', 'part', 'mill', 'ours', 'until', 'per', 'our', 'cry', 'eleven', 'former', 'toward', 'with', 'too', 'behind', 'anyone', 'off', 'then', 'less', 'whether', 'whatever', 'now', 'should', 'wherever', 'seeming', 'me', 'take', 'across', 'these', 'against', 'might', 'put', 'their', 'thru', 'own', 'than', 'do', 'so', 'such', 'around', 'becoming', 'however', 'wherein', 'every', 'since', 'beforehand', 'un', 'you', 'whoever', 'alone', 'bottom', 'myself', 'was', 'ten', 'her', 'how', 'my', 'them', 'done', 'system', 'into', 'very', 'whereas', 'us', 'be', 'thus', 'sixty', 'becomes', 'being', 'meanwhile', 'else', 'something', 'who', 'when', 'amongst', 'beside', 'will', 'together', 'on', 'thick', 'because', 'by', 'become', 'although', 'anywhere', 'last', 'upon', 'without', 'inc', 'onto', 'nothing', 'third', 'someone', 'therein', 'fire', 'mine', 'anyway', 'as', 'next', 'already', 'cannot', 'the', 'to', 'everywhere', 'herself'})\n",
      "fake    18765\n",
      "true    17153\n",
      "Name: label, dtype: int64 \n",
      " Shape of Data is  (35918, 2)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction import text \n",
    "additional_words=['reuters']\n",
    "stop_words = text.ENGLISH_STOP_WORDS.union(additional_words)\n",
    "print(stop_words)\n",
    "print(train['label'].value_counts(),'\\n Shape of Data is ',train.shape)\n",
    "corpus=train['text']\n",
    "labels=train['label']\n",
    "test_corpus=test['text']\n",
    "test_labels=test['label']\n",
    "cv=CountVectorizer(ngram_range=(1,1),lowercase=True,token_pattern='\\w{3,}',stop_words=stop_words)\n",
    "train_cv=cv.fit_transform(corpus)\n",
    "test_cv=cv.transform(test_corpus)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic F1_score 0.98452\n"
     ]
    }
   ],
   "source": [
    "log_model=LogisticRegression(solver=\"liblinear\", multi_class=\"auto\")\n",
    "log_model.fit(train_cv,labels)\n",
    "pred_labels=log_model.predict(test_cv)\n",
    "f1_score=round(metrics.f1_score(test_labels,pred_labels,average=\"weighted\"),5)\n",
    "weights=log_model.coef_\n",
    "print('Logistic F1_score',f1_score)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Show K1 and F1-Score for KNN Model \n",
      " Model  K-value  F1-Score\n",
      " KNN     1.0     0.8353 \n",
      " KNN     3.0     0.7884 \n",
      " KNN     5.0     0.7715 \n",
      " KNN     7.0     0.7635 \n",
      " KNN     9.0     0.7576 \n",
      " KNN    11.0     0.7533 \n",
      " KNN    13.0     0.7463 \n"
     ]
    }
   ],
   "source": [
    "knn_values=[1,3,5,7,9,11,13]\n",
    "df_k_stats=pd.DataFrame()\n",
    "knn_stats={'Model':'KNN','K-value':None,'F1-Score':None} #Create dictionary to hold KNN stats to append with dataframe\n",
    "for i in knn_values:\n",
    "    knn_stats['K-value'] = i #Store K-value within dictionary\n",
    "    knn_model = KNeighborsClassifier(n_neighbors = i) #Create KNN model\n",
    "    knn_model.fit(train_cv,labels) #Fit model on training data from CountVectorizer fit and transform\n",
    "    knn_pred=knn_model.predict(test_cv) #Predict on dev dataset\n",
    "    knn_model_f1=metrics.f1_score(test_labels,knn_pred,average=\"weighted\") #Get f1-score based on the dev labels and predicted values\n",
    "    knn_stats['F1-Score'] = round(knn_model_f1,4) #Make it pretty\n",
    "    df_k_stats = df_k_stats.append(knn_stats, ignore_index=True) #place the values in dataframe\n",
    "print('Show K1 and F1-Score for KNN Model','\\n',df_k_stats.to_string(index=False,justify='center'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Show Alpha and F1-Score for Naive-Bayes Model \n",
      "    Model      Alpha   F1-Score\n",
      "Naive-Bayes  0.00001   0.9507 \n",
      "Naive-Bayes  0.00010   0.9503 \n",
      "Naive-Bayes  0.00100   0.9499 \n",
      "Naive-Bayes  0.01000   0.9485 \n",
      "Naive-Bayes  0.10000   0.9462 \n",
      "Naive-Bayes  1.00000   0.9438 \n",
      "Naive-Bayes  2.00000   0.9427 \n",
      "Naive-Bayes  5.00000   0.9402 \n",
      "Naive-Bayes 10.00000   0.9377 \n"
     ]
    }
   ],
   "source": [
    "df_alpha_stats=pd.DataFrame() #Create dataframe to hold alpha stats\n",
    "alpha=[.00001,.0001,.001,.01,.1,1,2,5,10] #alpha-values for testing for Naive-Bayes model\n",
    "for i in alpha:\n",
    "    nb_stats={'Model':'Naive-Bayes','Alpha':None,'F1-Score':None} #Create dictionary to hold Naive-Bayes stats to append with dataframe\n",
    "    nb_stats['Alpha']=i #Store alpha-value within dictionary\n",
    "    nb_model=MultinomialNB(alpha=i) #Create Naive-Bayes model based on alpha value\n",
    "    nb_model.fit(train_cv,labels) #Fit model on training data from CountVectorizer fit and transform\n",
    "    nb_pred=nb_model.predict(test_cv) #Predict on dev dataset\n",
    "    nb_model_f1=metrics.f1_score(test_labels,nb_pred,average=\"weighted\") #Get f1-score based on the dev labels and predicted values\n",
    "    nb_stats['F1-Score']=round(nb_model_f1,4) #Make it pretty\n",
    "    df_alpha_stats=df_alpha_stats.append(nb_stats,ignore_index=True)  #place the values in dataframe\n",
    "print('\\nShow Alpha and F1-Score for Naive-Bayes Model','\\n',df_alpha_stats.to_string(index=False,justify='center'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>citing</td>\n",
       "      <td>1.152251</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>barack</td>\n",
       "      <td>1.207690</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>nov</td>\n",
       "      <td>1.432894</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>london</td>\n",
       "      <td>1.502781</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>monday</td>\n",
       "      <td>1.683132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>tuesday</td>\n",
       "      <td>1.775775</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>friday</td>\n",
       "      <td>1.895099</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>washington</td>\n",
       "      <td>2.038345</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>wednesday</td>\n",
       "      <td>2.068386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>thursday</td>\n",
       "      <td>2.188648</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words      true\n",
       "0      citing  1.152251\n",
       "1      barack  1.207690\n",
       "2         nov  1.432894\n",
       "3      london  1.502781\n",
       "4      monday  1.683132\n",
       "5     tuesday  1.775775\n",
       "6      friday  1.895099\n",
       "7  washington  2.038345\n",
       "8   wednesday  2.068386\n",
       "9    thursday  2.188648"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1.00000000e+00 8.45314810e-10 9.99940949e-01 ... 9.99991212e-01\n",
      " 1.35784612e-02 9.99954607e-01]\n"
     ]
    }
   ],
   "source": [
    "weights=log_model.coef_ #Get the weights of the logistic regression\n",
    "sorted_weights=np.argsort(weights)[:,-10:].flatten() #sort them in order to get the top 5 weights per topic\n",
    "topic_words=cv.get_feature_names_out()[sorted_weights] #Grab the words from the top 5 weights \n",
    "categories=['true','fake']\n",
    "topics=categories#set the topics to place in the dataframe\n",
    "df_topics=pd.DataFrame() #create dataframe\n",
    "df_topics['words']=pd.DataFrame(topic_words) #create the column of words for the top 20 words in each category\n",
    "for i in range(1): #create for loop to go through the topics\n",
    "    specific_weight=weights[i][sorted_weights] #Get the specific weight for that word\n",
    "    df_topics[topics[i]]=pd.DataFrame(specific_weight,columns=[topics[i]]) #Place the word and topics in the row\n",
    "display(df_topics) #showcase the topics and the words for the feature\n",
    "y_pred_prob = log_model.predict_proba(test_cv)[:, 1]\n",
    "print(y_pred_prob)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/rohin/opt/anaconda3/lib/python3.9/site-packages/sklearn/utils/deprecation.py:103: FutureWarning: Attribute `coef_` was deprecated in version 0.24 and will be removed in 1.1 (renaming of 0.26).\n",
      "  warnings.warn(msg, category=FutureWarning)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>words</th>\n",
       "      <th>true</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>united</td>\n",
       "      <td>-5.936620</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>republican</td>\n",
       "      <td>-5.882815</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>states</td>\n",
       "      <td>-5.879248</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>house</td>\n",
       "      <td>-5.866152</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>new</td>\n",
       "      <td>-5.840246</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>government</td>\n",
       "      <td>-5.747887</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>state</td>\n",
       "      <td>-5.635886</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>president</td>\n",
       "      <td>-5.339790</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>trump</td>\n",
       "      <td>-4.679511</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>said</td>\n",
       "      <td>-4.088865</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        words      true\n",
       "0      united -5.936620\n",
       "1  republican -5.882815\n",
       "2      states -5.879248\n",
       "3       house -5.866152\n",
       "4         new -5.840246\n",
       "5  government -5.747887\n",
       "6       state -5.635886\n",
       "7   president -5.339790\n",
       "8       trump -4.679511\n",
       "9        said -4.088865"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "weights=nb_model.coef_ #Get the weights of the logistic regression\n",
    "sorted_weights=np.argsort(weights)[:,-10:].flatten() #sort them in order to get the top 5 weights per topic\n",
    "topic_words=cv.get_feature_names_out()[sorted_weights] #Grab the words from the top 5 weights \n",
    "categories=['true','fake']\n",
    "topics=categories#set the topics to place in the dataframe\n",
    "df_topics=pd.DataFrame() #create dataframe\n",
    "df_topics['words']=pd.DataFrame(topic_words) #create the column of words for the top 20 words in each category\n",
    "for i in range(1): #create for loop to go through the topics\n",
    "    specific_weight=weights[i][sorted_weights] #Get the specific weight for that word\n",
    "    df_topics[topics[i]]=pd.DataFrame(specific_weight,columns=[topics[i]]) #Place the word and topics in the row\n",
    "display(df_topics) #showcase the topics and the words for the feature\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
